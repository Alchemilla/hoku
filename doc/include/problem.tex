\newcommand{\iFrame}{\mathcal{I}}
\newcommand{\kFrame}{\mathcal{K}}
%\newcommand{\vv}[1]{\overrightarrow{#1}}
\newcommand{\vv}[1]{#1} % Not doing anything special for vectors right now...

\section{Attitude Determination}\label{sec:attitudeDetermination}

\begin{figure}[ht]
    \centering{
%    \includegraphics[scale=0.23]{images/moving-coordinate-systems-edit.PNG}
    \input{include/floats/coordinate-systems}
    \caption{
    Visual of two coordinate frames: the inertial frame $\kFrame$, and the body frame $\iFrame$.
    Observation $j$ is described with vector $\vv{I_j}$ in the $\iFrame$ body frame.
    The same observation $j$ is described with vector $\vv{K_j}$ in the $\kFrame$ inertial frame.
    By aligning several observations in both frames, a spacecraft orientation $A^\nicefrac{\iFrame}{\kFrame}$ can be
    determined to take all points in $\kFrame$ to $\iFrame$.
    } \label{figure:coordinateSystem}
    }
\end{figure}

This section serves to give a brief overview into what attitude is, what Wahba's problem is, and the processing required
before the star identification can begin.

\subsection{General Attitude Determination}\label{subsec:generalAttitudeDetermination}
Attitude refers to the translation between how one system describes an object compared to how a different system
describes the same object.
These systems are referred to as \textit{reference frames}, and describe objects in terms of dimensions ($x_1, x_2, x_3,
\ldots$).
As an example, observer $A$ at the bottom of a mountain may describe the mountain itself as large and above itself.
Another observer $B$ on a helicopter hovering over the same mountain may describe it as small and below itself.
To find an attitude between $A$'s reference frame and $B$'s reference frame is to find some function $f(x_1, x_2, x_3,
\ldots)$ that is able to produce $B$'s description of the mountain with $A$'s observations.

In the context of spacecraft attitude from star tracking, there exist three reference frames: the \textit{body frame},
the \textit{sensor frame}, and the \textit{inertial frame}.
The body frame itself is fixed to the structure of the spacecraft, the sensor frame is fixed to the star tracker,
and the inertial frame refers to some non-accelerating frame.
All observations from the spacecraft exist in the sensor frame, but can easily be rotated to align with the body frame.
To simplify the problem, the body frame is used interchangeably with the sensor frame.
To describe the spacecraft itself, an inertial frame is convenient for simplifying the process of finding an attitude.
A star observed in the inertial frame is more predictable than the same star observed in a tumbling spacecraft.
Using all three, the goal of attitude determination becomes finding some method of translation between the inertial
frame and the body frame.

\begin{subequations}
    ~\autoref{figure:coordinateSystem} describes an inertial frame $\kFrame$ with a right hand set of three orthogonal
    vectors $\{\vv{u_1}, \vv{u_2}, \vv{u_3}\}$ and a body frame $\iFrame$ with another right hand set of three
    orthogonal vectors $\{\vv{v_1}, \vv{v_2}, \vv{v_3}\}$~\cite{RotationMatricies}.
    A \textit{rotation matrix} $A$ can be assembled to describe the basis vectors of $\kFrame$ in terms of $\iFrame$:
    \begin{align}
        \begin{bmatrix}
            \vv{v_1} \\
            \vv{v_2}  \\
            \vv{v_3}
        \end{bmatrix} &=
        \begin{bmatrix}
            \vv{v_1} \cdot \vv{u_1} & \vv{v_1} \cdot \vv{u_2} & \vv{v_1} \cdot \vv{u_3} \\
            \vv{v_2} \cdot \vv{u_1} & \vv{v_2} \cdot \vv{u_2} & \vv{v_2} \cdot \vv{u_3} \\
            \vv{v_3} \cdot \vv{u_1} & \vv{v_3} \cdot \vv{u_2} & \vv{v_3} \cdot \vv{u_3}
        \end{bmatrix}
        \begin{bmatrix}
            \vv{u_1} \\
            \vv{u_2}  \\
            \vv{u_3}
        \end{bmatrix} \\
        \begin{bmatrix}
            \vv{v_1} \\
            \vv{v_2}  \\
            \vv{v_3}
        \end{bmatrix} &=
        A^{\nicefrac{\iFrame}{\kFrame}}
        \begin{bmatrix}
            \vv{u_1} \\
            \vv{u_2}  \\
            \vv{u_3}
        \end{bmatrix}
    \end{align}
\end{subequations}
The issue here is that this rotation matrix $A$ is not given and that we need to account for noise in obtaining our
measurements.
This problem is known as \textit{Wahba's problem}, first posed by Gracie Wahba in 1965~\cite{Wahba}.
Wahba's problem states that finding the optimal $A$ involves minimizing the loss function below:
\begin{equation}
    L(A) = \frac{1}{2} \sum_j^n \vv{w_j} \left\| \vv{I_j} - A\vv{K_j} \right\|^2
\end{equation}
where $\vv{w_j}$ represents a non negative weight associated with the noise between the observations $\vv{I_j}$
in the body frame and $\vv{K_j}$ in the inertial frame.

\begin{subequations}
    For $n > 2$, Wahba's problem exists as an optimization problem.
    In the $n = 2$ case though, the \textit{TRIAD method} (short for TRIaxial Attitude Determination) exists as a
    closed form solution~\cite{ClosedForm}.
    This algorithm starts by constructing two sets of basis vectors: one attached to the body referential (two
    observations in the body frame) $\left[ \vv{t_{1I}} \ \vv{t_{2I}} \ \vv{t_{3I}} \right]$ and another attached to
    the inertial referential (two observations in the inertial frame) $\left[ \vv{t_{2I}} \ \vv{t_{2K}} \ \vv{t_{3K}}
    \right]$~\cite{TRIAD, TRIADOriginal}.
    This is known as the triad frame:
    \begin{alignat}{2}
        \vv{t_{1I}} &= \frac{\vv{v_1}}{\left| \vv{v_1} \right|} &\vv{t_{2I}} &{}={}&
            \frac{\vv{u_1}}{\left| \vv{u_1} \right|} \\
        \vv{t_{2I}} &= \frac{\vv{v_1} \times \vv{v_2}}{\left| \vv{v_1} \times \vv{v_2} \right|} \ \ \ \ \ \ \ \
            &\vv{t_{2K}} &{}={}& \frac{\vv{u_1} \times \vv{u_2}}{\left| \vv{u_1} \times \vv{u_2} \right|} \\
        \vv{t_{3I}} &= \vv{t_{1I}} \times \vv{t_{2I}} &\vv{t_{3K}} &{}={}& \vv{t_{2I}} \times \vv{t_{2K}}
    \end{alignat}
\end{subequations}
Getting from frame $\kFrame$ to $\iFrame$ now simplifies to multiplication of the triad frame base change matrices:
\begin{equation}
    A =
    \begin{bmatrix}
        \vv{t_{1K}} & \vv{t_{2K}} & \vv{t_{3K}}
    \end{bmatrix}
    \begin{bmatrix}
        \vv{t_{1I}} & \vv{t_{2I}} & \vv{t_{3I}}
    \end{bmatrix}^T
\end{equation}
For all instances where a rotation between the inertial and body frames was required, the TRIAD algorithm was used.

\subsection{Stellar Based Attitude Determination}\label{subsec:stellarBasedAttitudeDetermination}
\begin{subequations}
    Relative to our solar system, the majority of bright stars ($m < 6.0$, or visible from the Earth with the naked
    eye) do not visibly move.
    For simplicity, we make the assumption here that all stars in $\kFrame$ are fixed and exist in a inertial frame
    known as the \textit{Earth centered inertial} frame, or ECI frame.
    The star vectors themselves come from star catalogs, the majority of which use the ECI frame and record the
    positions of stars as points lying on a unit sphere (celestial sphere)~\cite{Tappe}.
    Two pieces of information are given here: right ascension $\alpha$ (equivalent to latitude on Earth) and
    declination $\delta$ (equivalent to longitude).
    Representing some spherical point $(\alpha, \delta, r)$ in 3D Cartesian space involves the following:
    \begin{align} \label{eq:sphereToCartesian}
        x &= r \cos(\delta) \cos(\alpha) \\
        y &= r \cos(\delta) \sin(\alpha) \\
        z &= r \sin(\delta)
    \end{align}
    where both $\alpha$ and $\delta$ are in degrees, and $r$ represents some constant distance from Earth.
    $\vv{K_j}$ represents a point obtained from a star catalog that lies in the ECI frame, $r$ units away from Earth.
\end{subequations}

$\vv{I_j}$ represents a 2D point obtained from the star tracker projected into 3D space.
A basic star tracker is composed of a camera, a computer for determining orientation, and a link back to the main
computer.
After taking the picture, the pixel positions of potential stars in the image are determined.
This involves finding bright blobs in the image, and computing each blob's center of mass to get a point ($x, y$).
Through some 2D to 3D transformation process involving the camera's hardware (i.e.\ field of view, focal point,
etc\ldots), a 3D point is then obtained~\cite{Tappe}.
This point is then used to compare stars in the inertial frame.
%    To align these stars with the ones in the catalog, the inverse Mercator mapping is used [CITE ME]:
%    \begin{align}
%        x &= k \cos\left( \frac{x}{R}  \right) \cos\left(2 * \arctan\left(\exp\left(\frac{y}{R}\right)\right) -
%            \frac{\pi}{2}\right) \\
%        y &= k \cos\left( \frac{x}{R}  \right) \sin\left(2 * \arctan\left(\exp\left(\frac{y}{R}\right)\right) -
%            \frac{\pi}{2}\right) \\
%        z &= k \sin\left( \frac{x}{R}  \right)
%    \end{align}

The next issue is the focus of this paper: determining which observation from the star tracker frame $\iFrame$
corresponds which observation from the star catalog frame $\kFrame$.
Once these are recognized, the situation reduces to Wahba's problem to find the optimal attitude~\cite{Survey}.
