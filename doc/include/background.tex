\section{Introduction}\label{sec:introduction}
Ancient mariners could look up at the night sky, point out which stars they were looking at, and navigate across the
globe without the use of maps.
\textit{Constellation queries} refer to approaches to determine which stars are in the sky.
Given an image of the sky, to query for a constellation is to map a select few bright spots in image to stars in
a stellar repository.
\textit{Lost-in-space} refers to an additional constraint on the problem: the absence of knowing where we took
the picture and how we pointed the camera.

%Ancient mariners could look up at the night sky, point out which stars they were looking at, and navigate across the
%globe without the use of maps.
%\textit{Star identification algorithms} refer to computational approaches to determining which stars are in the sky.
%Given an image of the sky, star identification is matching the bright spots in an image to stars in an astronomical
%catalog.
%The device that performs these computations is the star tracker, much like the navigators on the ship.
%\textit{Lost-in-space} refers to an additional constraint on the problem: the absence of knowing where we took
%the picture and how we pointed the camera.

This problem is most prevalent in designing LEO (low Earth orbit) spacecraft.
In order for a craft to point a payload, direct its thrusters, or orient its solar panels, an accurate
\textit{attitude} (another term for orientation) must be known.
There are a few known landmarks in space where some attitude can be extracted (the Earth, the Sun), but this
requires constant direction towards just these objects.
Star trackers do not limit themselves to a single object, rather they use multiple stars within their field of view
to determine their orientation.

%There exist roughly $4{,}500$ stars in the sky visible to the human eye.
%For an image of $n$ stars, the naive approach would be compute $C(4{,}500, n)$ combinations from this collection and
%compare each to some subset of stars found in the image.
%For $n\seq 3$, this requires over $10^{10}$ comparisons.
%As an alternative, we sacrifice storage and precision for speed by searching a separate collection which indexes the
%${\sim}4{,}500$ stars by one or more features.
%When this subset is identified, we determine and return the orientation of the image relative to collection
%of ${\sim}4{,}500$ stars.

This research is motivated by a growing difference in the number of stellar attitude determination methods and
empirical comparison between each of these methods in a more systematic manner for star tracker development.
Interchangeable factors are abstracted away (camera hardware, blob detection, etc\ldots) to focus more on how each
query strategy matches stars in an image to stars in a database.
This paper aims to contribute a hardware independent comparison process, an algorithmic description of several
query strategies, as well as runtime and catalog access analysis of these strategies under various types of noise.
The process of identifying blobs in an image, constructing the image coordinate system, and efficiently querying
static databases are not addressed here.

\subsection{Stellar Based Attitude Determination}\label{subsec:stellarBasedAttitudeDetermination}
%Attitude refers to the translation between how one system describes an object compared to how a different system
%describes the same object.
%
%In the context of spacecraft attitude for star identification, there exist three reference frames: the
%\textit{body frame}, the \textit{sensor frame}, and the \textit{inertial frame}.
%The body frame itself is fixed to the structure of the spacecraft, the sensor frame is fixed to the star tracker,
%and the inertial frame refers to some non-accelerating frame in which stellar objects are recorded.
%All observations from the spacecraft exist in the sensor frame, but can easily be rotated to align with the body frame
%(the sensor itself is fixed to the spacecraft chassis).
%Consequently, the body frame is used interchangeably with the sensor frame.
%To describe the craft itself, an inertial frame is required for finding a practical attitude.
%A star observed in the inertial frame is more predictable than the same star observed in a tumbling spacecraft, aiding
%the usage of the attitude with orientation dependent processes.
%Using all three, the goal of attitude determination becomes finding some method of translation between the inertial
%frame and the body frame.

Let $\kFrame$ describe an inertial reference frame and $\iFrame$ describe a body reference
frame~\cite{wie:spaceVehicleDynamics}.
To find a \textit{rotation matrix} $A$ that describes the basis vectors of $\kFrame$ in terms of $\iFrame$ but accounts
for the noise of each measurement is known as \textit{Wahba's problem}, first posed by Gracie Wahba in
1965~\cite{wahba:attitudeEstimationProblem}.
Wahba's problem states that finding the optimal $A$ involves minimizing the loss function below:
\begin{equation}
    L(A) = \frac{1}{2} \sum_j^n \vv{w_j} \left\| \vv{I_j} - A\vv{K_j} \right\|^2
\end{equation}
where $\vv{w_j}$ represents a non negative weight associated with the noise between the observations $\vv{I_j}$
in the body frame and $\vv{K_j}$ in the inertial frame.
For all instances where Wahba's problem appeared, the \textit{TRIAD method} (short for TRIaxial Attitude Determination)
was used as a closed form solution~\cite{markley:attitudeDeterminationTwoVectors}.

%
%For $n \!>\! 2$, Wahba's problem exists as an optimization problem.
%In the $n\seq2$ case though, the \textit{TRIAD method} (short for TRIaxial Attitude Determination) exists as a
%closed form solution~\cite{markley:attitudeDeterminationTwoVectors}.
%This algorithm starts by constructing two sets of basis vectors: one attached to the body referential (two
%observations in the body frame) $\left[ \vv{t_{1I}} \ \vv{t_{2I}} \ \vv{t_{3I}} \right]$ and another attached to
%the inertial referential (two observations in the inertial frame) $\left[ \vv{t_{2I}} \ \vv{t_{2K}} \ \vv{t_{3K}}
%\right]$~\cite{benet:swisscubeAttitudeDetermination,black:passiveAttitudeDetermination}.
%This is known as the triad frame:
%\begin{alignat}{4}
%    \vv{t_{1I}} &= \frac{\vv{v_1}}{\left| \vv{v_1} \right|} &\vv{t_{2I}} &{}={}&
%    \frac{\vv{u_1}}{\left| \vv{u_1} \right|} \ \ \ \ \ \ \  \\
%    \vv{t_{2I}} &= \frac{\vv{v_1} \times \vv{v_2}}{\left| \vv{v_1} \times \vv{v_2} \right|} \ \ \ \ \ \ \ \
%        &\vv{t_{2K}} &{}={}& \frac{\vv{u_1} \times \vv{u_2}}{\left| \vv{u_1} \times \vv{u_2} \right|} \\
%    \vv{t_{3I}} &= \vv{t_{1I}} \times \vv{t_{2I}} &\vv{t_{3K}} &{}={}& \vv{t_{2I}} \times \vv{t_{2K}}
%\end{alignat}
%Getting from frame $\kFrame$ to $\iFrame$ now simplifies to multiplication of the triad frame base change matrices:
%\begin{equation}
%    A =
%    \begin{bmatrix}
%        \vv{t_{1K}} & \vv{t_{2K}} & \vv{t_{3K}}
%    \end{bmatrix}
%    \begin{bmatrix}
%        \vv{t_{1I}} & \vv{t_{2I}} & \vv{t_{3I}}
%    \end{bmatrix}^T
%\end{equation}

%\begin{subequations}
%Relative to our solar system, the majority of bright stars ($m \!<\! 6.0$, or visible from the Earth with the naked
%eye) do not visibly move.
%Relative to our solar system, the majority of stars visible from Earth with the naked eye do not visibly move.
For simplicity, we make the assumption here that all stars in $\kFrame$ are fixed and exist in an inertial frame
known as the \textit{Earth centered inertial} frame, or ECI frame.
The star vectors themselves come from astronomical catalogs, recorded as points lying on the celestial
sphere~\cite{tappe:starTrackerDevelopment}.
Two pieces of information are given here: right ascension $\alpha$ (equivalent to latitude on Earth) and
declination $\delta$ (equivalent to longitude).
$\vv{K_j}$ represents a point $\left( \alpha, \delta \right)$ in a 3D spherical frame with constant radius,
projected to 3D Cartesian space.
%    Representing some spherical point $(\alpha, \delta, r)$ in 3D Cartesian space involves the following:
%    \begin{align} \label{eq:sphereToCartesian}
%    x &= r \cos(\delta) \cos(\alpha) \\
%    y &= r \cos(\delta) \sin(\alpha) \\
%    z &= r \sin(\delta)
%    \end{align}
%    where both $\alpha$ and $\delta$ are in degrees, and $r$ represents some constant distance from Earth.
%    $\vv{K_j}$ represents a point obtained from a star catalog that lies in the ECI frame, $r$ units away from Earth.
%\end{subequations}

Let $\vv{I_j}$ represent a 3D point projected from a 2D observation taken by the star tracker.
A basic star tracker is composed of a camera, a computer for determining orientation, and a link back to the main
computer.
After taking the picture, the pixel positions of potential stars in the image are determined.
This involves finding bright blobs in the image, and computing each blob's center of mass to get a point ($x, y$).
Through some 2D to 3D transformation process involving the camera's lens structure, a 3D point is then
obtained~\cite{tappe:starTrackerDevelopment}.
%    To align these stars with the ones in the catalog, the inverse Mercator mapping is used [CITE ME]:
%    \begin{align}
%        x &= k \cos\left( \frac{x}{R}  \right) \cos\left(2 * \arctan\left(\exp\left(\frac{y}{R}\right)\right) -
%            \frac{\pi}{2}\right) \\
%        y &= k \cos\left( \frac{x}{R}  \right) \sin\left(2 * \arctan\left(\exp\left(\frac{y}{R}\right)\right) -
%            \frac{\pi}{2}\right) \\
%        z &= k \sin\left( \frac{x}{R}  \right)
%    \end{align}

The next issue is the focus of this paper: determining which observation from the star tracker frame $\iFrame$
corresponds to which observation from the star catalog frame $\kFrame$.
Once this correspondence is found, Wahba's problem is solved to obtain $A$ and this is returned to the main computer.
